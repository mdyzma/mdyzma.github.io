<!DOCTYPE html>
<html lang="en">

  <!-- Begin Jekyll SEO tag v2.2.3 -->
<title>Jupyter Notebook - python based lab book | Consider Python</title>
<meta property="og:title" content="Jupyter Notebook - python based lab book" />
<meta name="author" content="Michal Dyzma" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Data analysis using Jupyter Notebook. Natural sciences more and more rely on skills related to Data Science. Experiments produce more and more data, and skilled researcher has to know how to deal with variety of data and sometime very large datasets. Anaconda Python Distribution offers large set of great tools to manipulate any kind of data “out of the box”. Multitude of community packages allows to read, analyze and report all kinds of data produced by science. It is caused mostly by simple fact, that scientific community is developing it’s tools mostly in Python. How to work with small and large data in python and make Jupyter Notebook your lab-book? Check this article." />
<meta property="og:description" content="Data analysis using Jupyter Notebook. Natural sciences more and more rely on skills related to Data Science. Experiments produce more and more data, and skilled researcher has to know how to deal with variety of data and sometime very large datasets. Anaconda Python Distribution offers large set of great tools to manipulate any kind of data “out of the box”. Multitude of community packages allows to read, analyze and report all kinds of data produced by science. It is caused mostly by simple fact, that scientific community is developing it’s tools mostly in Python. How to work with small and large data in python and make Jupyter Notebook your lab-book? Check this article." />
<link rel="canonical" href="http://localhost:4000/2017/03/03/jupyter-notebook-lab-book/" />
<meta property="og:url" content="http://localhost:4000/2017/03/03/jupyter-notebook-lab-book/" />
<meta property="og:site_name" content="Consider Python" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-03-03T16:28:54+01:00" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@MichalDyzma" />
<meta name="twitter:creator" content="@Michal Dyzma" />
<meta property="fb:admins" content="mdyzma" />
<meta property="article:publisher" content="mdyzma" />
<meta property="fb:app_id" content="422251294815916" />
<script type="application/ld+json">
{"@context":"http://schema.org","@type":"BlogPosting","headline":"Jupyter Notebook - python based lab book","author":{"@type":"Person","name":"Michal Dyzma"},"datePublished":"2017-03-03T16:28:54+01:00","dateModified":"2017-03-03T16:28:54+01:00","description":"Data analysis using Jupyter Notebook. Natural sciences more and more rely on skills related to Data Science. Experiments produce more and more data, and skilled researcher has to know how to deal with variety of data and sometime very large datasets. Anaconda Python Distribution offers large set of great tools to manipulate any kind of data “out of the box”. Multitude of community packages allows to read, analyze and report all kinds of data produced by science. It is caused mostly by simple fact, that scientific community is developing it’s tools mostly in Python. How to work with small and large data in python and make Jupyter Notebook your lab-book? Check this article.","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/md-logo.png"},"name":"Michal Dyzma"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2017/03/03/jupyter-notebook-lab-book/"},"url":"http://localhost:4000/2017/03/03/jupyter-notebook-lab-book/"}</script>
<!-- End Jekyll SEO tag -->

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>Jupyter Notebook - python based lab book</title>
  <meta name="description" content="Data analysis using Jupyter Notebook. Natural sciences more and more rely on skills related to Data Science. Experiments produce more and more data, and skilled researcher has to know how to deal with variety of data and sometime very large datasets. Anaconda Python Distribution offers large set of great tools to manipulate any kind of data “out of the box”. Multitude of community packages allows to read, analyze and report all kinds of data produced by science. It is caused mostly by simple fact, that scientific community is developing it’s tools mostly in Python. How to work with small and large data in python and make Jupyter Notebook your lab-book? Check this article.">
  <meta name="keywords" content="python, jupyter-notebook, data-science">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/2017/03/03/jupyter-notebook-lab-book/">
  
  
  <link rel="alternate" type="application/rss+xml" title="Consider Python" href="http://localhost:4000/feed.xml">

  

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="MichalDyzma">
  <meta name="twitter:title" content="Jupyter Notebook - python based lab book">
  <meta name="twitter:description" content="Data analysis using Jupyter Notebook. Natural sciences more and more rely on skills related to Data Science. Experiments produce more and more data, and skilled researcher has to know how to deal w...">
  
    <meta name="twitter:creator" content="MichalDyzma">
  
  

  <script type="text/javascript">
  WebFontConfig = {
    google: { families: [ 'Bitter:400,700,400italic:latin' ] }
  };
  (function() {
    var wf = document.createElement('script');
    wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
      '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
    wf.type = 'text/javascript';
    wf.async = 'true';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(wf, s);
  })();
</script>

<!-- Font awesome -->
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  
  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-97434888-1', 'auto');
    ga('send', 'pageview');

  </script>


  
  <!-- Google Adsense -->
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: ca-pub-4566255347044004,
    enable_page_level_ads: true
  });
</script>


</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Consider Python</a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="/">Home</a>
      
        
        <a class="page-link" href="/archives/">Archives</a>
      
        
        <a class="page-link" href="/about/">About</a>
      
        
        <a class="page-link" href="https://github.com/mdyzma/">GitHub</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    
      <h1 class="post-title" itemprop="name headline">Jupyter Notebook - python based lab book</h1>
    
    <p class="post-meta"><time datetime="2017-03-03T16:28:54+01:00" itemprop="datePublished">Mar 3, 2017</time> • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Michal Dyzma</span></span> • 
  
  
    
      <a href="/categories/python/">python</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
      <a href="/categories/jupyter-notebook/">jupyter-notebook</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
      <a href="/categories/data-science/">data-science</a>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

</p>
  </header>

  <div style="padding: 5px 0 5px 0;">
<span class="reading-time" title="Estimated read time">
  
  
    <i class="fa fa-clock-o" aria-hidden="true"></i> Estimated read time: <b>25 mins </b>
  
</span>
</div>

  <div class="post-content" itemprop="articleBody">

    <p>Data analysis using <strong>Jupyter Notebook</strong>. Natural sciences more and more rely on skills related to Data Science. Experiments produce more and more data, and skilled researcher has to know how to deal with variety of data and sometime very large datasets. <strong>Anaconda</strong> Python Distribution offers large set of great tools to manipulate any kind of data “out of the box”. Multitude of community packages allows to read, analyze and report all kinds of data produced by science. It is caused mostly by simple fact, that scientific community is developing it’s tools mostly in Python. How to work with small and large data in python and make Jupyter Notebook your lab-book? Check this article.</p>

<p><br /></p>
<div class="alert alert-info" role="alert" style="text-align: justify; vertical-align:middle;">
Notebooks and related data files from this article can be downloaded from this <a href="https://github.com/mdyzma/blog-src-files/tree/master/2017-03-03-jupyter-notebook-lab-book">GitHub repository</a>
</div>

<h1 id="install-anaconda">Install Anaconda</h1>

<blockquote>
  <p><em>Data Science</em> skills are essential for every decent researcher.</p>
</blockquote>

<p><a href="https://www.continuum.io/DOWNLOADS">Anaconda Python Distribution</a> prepared by Continuum Analytics is the most comprehensive and free bundle of Python software dedicated to <strong>Data Science</strong>.</p>

<p>I strongly recommended to use <a href="https://www.continuum.io/DOWNLOADS">Anaconda distribution</a>, which will install Python interpreter, the Jupyter Notebook, and several other packages commonly used in data science and this tutorial. If you choose Anaconda 3, your interpreter will be of version 3.6 (current version) or higher (3.7 alpha is already available).</p>

<p>Execute script and just follow instructions from installation program (your current version may differ from the one listed here):</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">&gt; </span>wget https://repo.continuum.io/archive/Anaconda3-4.3.1-Linux-x86_64.sh

--2017-03-03 19:36:37--  https://repo.continuum.io/archive/Anaconda3-4.3.1-Linux-x86_64.sh
Resolving repo.continuum.io <span class="o">(</span>repo.continuum.io<span class="o">)</span>... 104.16.18.10, 104.16.19.10, 2400:cb00:2048:1::6810:130a, ...
Connecting to repo.continuum.io <span class="o">(</span>repo.continuum.io<span class="o">)</span>|104.16.18.10|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 497343851 <span class="o">(</span>474M<span class="o">)</span> <span class="o">[</span>application/x-sh]
Saving to: <span class="s1">'Anaconda3-4.3.1-Linux-x86_64.sh'</span>

Anaconda3-4.3.1-Linux-x86_64.sh     100%[<span class="o">==========================================</span>&gt;] 474.30M  14.1MB/s <span class="k">in </span>34s

2017-03-03 19:37:12 <span class="o">(</span>13.8 MB/s<span class="o">)</span> - <span class="s1">'Anaconda3-4.3.1-Linux-x86_64.sh'</span> saved <span class="o">[</span>497343851/497343851]

<span class="gp">&gt; </span>bash ./Anaconda3-4.3.1-Linux-x86_64.sh</code></pre></figure>

<p>To make sure software is up to date, run:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">&gt; </span>conda update --all</code></pre></figure>

<p>Anaconda will install nearly 200 packages (182 to be exact), including most important for this tutorial: Jupyter Notebook, ipython, pandas, numpy, statsmodels</p>

<h1 id="anaconda-channels">Anaconda channels</h1>

<p><code class="highlighter-rouge">conda</code> is built in Anaconda package manager, which uses default, maintained by Continuum Analytics python packages repository. Some packages are distributed in repositories owned by groups other than Anaconda team. Repositories are called channels. One can indicate channel simply by choosing <code class="highlighter-rouge">-c</code> or <code class="highlighter-rouge">--channel</code> flag during invoking <code class="highlighter-rouge">conda install</code> command. Some of the channels are supported by continuum Analytics, like <code class="highlighter-rouge">conda-forge</code>, <code class="highlighter-rouge">omnia</code> or <code class="highlighter-rouge">r</code>. They are full of excellent packages developed by Anaconda community. Every time I mention I want to use other channel than default, conda will check this repositories for available packages. It is possible to add this channels to the <code class="highlighter-rouge">.condarc</code> file (see: <a href="https://conda.io/docs/config.html#the-conda-configuration-file-condarc">here</a>). First config file must be created by running <code class="highlighter-rouge">conda config</code> command. If other version of this file is placed in Anaconda installation root directory it will override  users home configuration. to notify package manager, that every time  I want to install something this channels should be checked. Order of repositories is important. In case packages are deployed to both repositories listed in channels section, last repository super-seeds all above it. Example file looks like this:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">channels:
    - omnia
    - conda-forge
    - r
    - defaults

show_channel_urls: True

proxy_servers:
    http: http://user:pass@corp.com:8080
    https: https://user:pass@corp.com:8080</code></pre></figure>

<p>Last group of inputs is very important for users behind corporate proxy, which will block <code class="highlighter-rouge">conda</code> package lookup, unless correct settings are provided. Additionally one can alway use official python package manager <code class="highlighter-rouge">pip</code> in parallel to <code class="highlighter-rouge">conda</code>. Conda is able to sense origin of the package and shows this during package listing. Pip checks <a href="https://pypi.python.org/pypi">PyPI</a> (Python Packages Index) repository for python packages (which stores nearly 110 000 packages).</p>

<p>Another great part about Anaconda and Jupyter Notebook. It is cross-platform, which means, that Notebook files created on one system will open on other system with similar package configuration.</p>

<h1 id="jupyter-notebook--jupyter-lab">Jupyter Notebook / Jupyter Lab</h1>

<p>Jupyter Notebook allows to create and share documents that contain live code, equations, visualizations and explanatory text. Text may be written in markdown markup  language. Code can produce rich output such as images, videos, LaTeX, and JavaScript. Interactive widgets can be used to manipulate and visualize data in real time.
Alternatively you may add path to the existing Jupyter notebook file with <code class="highlighter-rouge">.ipybn</code> extension. If you add path to the notebook file ( extension <code class="highlighter-rouge">.ipynb</code>), it will be opened in the location of the file. Jupyter automatically runs a local server.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">&gt; </span>jupyter notebook

<span class="o">[</span>I 21:09:38.658 NotebookApp] Serving notebooks from <span class="nb">local </span>directory: /home/mdyzma/
<span class="o">[</span>I 21:09:38.659 NotebookApp] 0 active kernels
<span class="o">[</span>I 21:09:38.660 NotebookApp] The Jupyter Notebook is running at: http://localhost:8888/?token<span class="o">=</span>c6a93623006ede30a579af4d7e693909abd90c98224916ee
<span class="o">[</span>I 21:09:38.660 NotebookApp] Use Control-C to stop this server and shut down all kernels <span class="o">(</span>twice to skip confirmation<span class="o">)</span>. <span class="o">[</span>C 21:09:38.665 NotebookApp]

    Copy/paste this URL into your browser when you connect <span class="k">for </span>the first <span class="nb">time</span>,
    to login with a token:
        http://localhost:8888/?token<span class="o">=</span>c6a93623006ede30a579af4d7e693909abd90c98224916ee
<span class="o">[</span>I 21:09:39.005 NotebookApp] Accepting one-time-token-authenticated connection from ::1</code></pre></figure>

<p>It should start notebook server in your browser (default address: <a href="http://localhost:8888/tree">http://127.0.0.1:8888</a>):</p>

<p><img src="/assets/2017-03-03/jupyter-notebook.png" alt="notebook" /></p>

<p>There is a handy collection of extensions that add functionality to the Jupyter notebook. Extensions are grouped in package <a href="https://github.com/ipython-contrib/jupyter_contrib_nbextensions"><code class="highlighter-rouge">nbextensions</code></a>, which is not included in fresh Anaconda installation and I will install it using conda:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">&gt; </span>conda install -c conda-forge jupyter_contrib_nbextensions
Fetching package metadata .............
Solving package specifications: .

Package plan <span class="k">for </span>installation <span class="k">in </span>environment /home/mdyzma/anaconda3:

The following NEW packages will be INSTALLED:

    jupyter_contrib_core:              0.3.1-py36_0   conda-forge
    jupyter_contrib_nbextensions:      0.2.8-py36_1   conda-forge
    jupyter_highlight_selected_word:   0.0.10-py36_0  conda-forge
    jupyter_latex_envs:                1.3.8.2-py36_1 conda-forge
    jupyter_nbextensions_configurator: 0.2.5-py36_0   conda-forge

The following packages will be UPDATED:

    conda:                             4.3.21-py36_0              --&gt; 4.3.21-py36_1 conda-forge

The following packages will be SUPERSEDED by a higher-priority channel:

    conda-env:                         2.6.0-0                    --&gt; 2.6.0-0       conda-forge

Proceed <span class="o">([</span>y]/n<span class="o">)</span>? y


conda-env-2.6. 100% |###############################| Time: 0:00:00 206.58 kB/s
conda-4.3.21-p 100% |###############################| Time: 0:00:01 281.65 kB/s
jupyter_contri 100% |###############################| Time: 0:00:00 417.99 kB/s
jupyter_highli 100% |###############################| Time: 0:00:00 793.82 kB/s
jupyter_latex_ 100% |###############################| Time: 0:00:02 324.68 kB/s
jupyter_nbexte 100% |###############################| Time: 0:00:01 442.23 kB/s
jupyter_contri 100% |###############################| Time: 0:00:03   5.47 MB/s</code></pre></figure>

<p>Because I used conda it will automatically register all extensions and copy necessary <code class="highlighter-rouge">javascript</code> and <code class="highlighter-rouge">css</code> files in Jupyter environment for me. If I used pip instead, I would have to fetch additional command: <code class="highlighter-rouge">jupyter contrib nbextension install --user</code></p>

<p>Jupyter Lab is new project of Jupyter team, which eventually will replace good old notebook, but currently it is in very early alpha release version and it is not recommended to be used in any serious project. It has built in file manager, image browser, documentation and many, many other. And one disadvantage: <code class="highlighter-rouge">ipywidgets</code> and <code class="highlighter-rouge">nbextensions</code> do not work yet or their functionality must be loaded through lab extensions system, which is not very convenient. Another handy extension is <a href="https://github.com/rasbt/watermark"><code class="highlighter-rouge">watermark</code></a> package. It will timestamp notebooks and provide basic python configuration info. I will fetch latest version from GitHub:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">&gt; </span>pip install -e git+https://github.com/rasbt/watermark#egg<span class="o">=</span>watermark
Obtaining watermark from git+https://github.com/rasbt/watermark#egg<span class="o">=</span>watermark
  Cloning https://github.com/rasbt/watermark to /home/mdyzma/watermark
Installing collected packages: watermark
  Running setup.py develop <span class="k">for </span>watermark
Successfully installed watermark</code></pre></figure>

<p>Jupyter lab is not accessible in Anaconda distribution out of the box and must be installed. One can do it with default package manager from <code class="highlighter-rouge">conda-forge</code> channel:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">&gt; </span>conda install -c conda-forge jupyterlab
Fetching package metadata .............
Solving package specifications: .

Package plan <span class="k">for </span>installation <span class="k">in </span>environment /home/mdyzma/anaconda3:

The following NEW packages will be INSTALLED:

    jupyterlab:          0.23.2-py36_0 conda-forge
    jupyterlab_launcher: 0.2.9-py36_0  conda-forge

The following packages will be SUPERSEDED by a higher-priority channel:

    conda:               4.3.21-py36_0             --&gt; 4.3.21-py36_0 conda-forge
    conda-env:           2.6.0-0                   --&gt; 2.6.0-0       conda-forge

Proceed <span class="o">([</span>y]/n<span class="o">)</span>? y

conda-env-2.6. 100% |###############################| Time: 0:00:00  73.67 kB/s
conda-4.3.21-p 100% |###############################| Time: 0:00:01 378.40 kB/s
jupyterlab_lau 100% |###############################| Time: 0:00:00   1.18 MB/s
jupyterlab-0.2 100% |###############################| Time: 0:00:01   1.34 MB/s</code></pre></figure>

<p>Lab environment can be started using <code class="highlighter-rouge">jupyter lab</code> command. It should start in default browser under this address: <a href="http://localhost:8888/lab">http://127.0.0.1:8888</a>.</p>

<p><img src="/assets/2017-03-03/jupyter-lab.png" alt="lab" /></p>

<p>More information about this project and development plans can be found <a href="https://github.com/jupyterlab/jupyterlab">here</a>.</p>

<p>Simple <code class="highlighter-rouge">conda list</code> shows all packages installed in current environment. Main tools I will use in this tutorial include:</p>

<ul>
  <li><code class="highlighter-rouge">numpy</code> - array calculations</li>
  <li><code class="highlighter-rouge">sympy</code> - symbolic mathematics</li>
  <li><code class="highlighter-rouge">matplotlib</code> - 2D plotting</li>
  <li><code class="highlighter-rouge">statsmodels</code> - statistical models</li>
  <li><code class="highlighter-rouge">pandas</code> - data structures and analysis</li>
</ul>

<p>which are part of SciPy - python based scientific ecosystem. <a href="http://www.numpy.org">Numpy</a> and <a href="http://pandas.pydata.org">Pandas</a> alone have enormous documentations, which are worth to check. Huge advantage of notebook environment is that it allows to compute and manipulate data directly and export entire notebook in various formats, to share with other. There is also <code class="highlighter-rouge">JupyterHub</code>, providing access to the notebook for multiple users, which can be used as a official project documentation  in secure location and controlled access. Check <a href="https://jupyterhub.readthedocs.io/en/latest/">JupyterHub</a> documentation to learn more.</p>

<h1 id="experiments-examples">Experiments examples:</h1>

<p>To present power enclosed in python and jupyter notebook I will create several scenarios of typical experiments conducted in labs. It will cover data acquisition, modeling, visualization and data storage.</p>

<h2 id="protein-concentration">Protein concentration</h2>

<p>Example of simple experiment with data from VIS spectrophotometric experiment. Lets assume we have solution with protein colored by protein dye. For a uniform absorbing solution the proportion of light passing through is called the transmittance: \(T\), and the proportion of light absorbed by molecules in the medium is absorbance, \(Abs\). Experiment consists of three steps:</p>

<ol>
  <li>Determine the absorption spectra \(\lambda_{max}\)</li>
  <li>Calculate the extinction coefficient (\(\epsilon\)) of the standards.</li>
  <li>Determine the concentration of proteins in solution</li>
</ol>

<!-- #### Theoretical background

For a uniform absorbing solution  the proportion of light passing through is called the transmittance: \\(T\\), and the proportion of light absorbed by molecules in the medium is absorbance, \\(Abs\\). 

Transmittance is defined as:

$$T =  \frac{I}{I_{o}} $$

where:

* \\(I_o\\) is intensity of the incident radiation entering the medium.
* \\(I\\) = intensity of the transmitted radiation leaving the medium.


T can be expressed as percent transmittance, \\(%T\\):

$$%T = \frac{I}{I_{o}} \times 100$$

The relationship between percent transmittance (\\(\%T\\)) and absorbance (\\(Abs\\)) is given by the following equation:

$$Abs = 2 - log (\%T) $$

From above equation we can see, that probe, which absorbs 100% of the light will have transmittance 100% and absorbance equal 2 \\((log_{10} 100 = 2)\\), while completely transparent sample will have absorbance 0. Therefore theoretical span of Absorbance values range from 0 to 2, however Beer-Lambert's law is most accurate in range 0.05 to 0.7 \\(Abs\\).

The Beer-Lambert Law states that Absorbance is proportional to the concentration of the absorbing molecules, the length of light-path through the medium and the molar extinction coefficient:

$$ Abs = \epsilon \cdot c \cdot l $$

where:

* \\(Abs\\) – absorbance
* \\(\epsilon\\) – light extinction coefficient at max absorption wavelength \\(\lambda_{max}\\)
* \\(c\\) – substance concentration
* \\(l\\) – length of light-path

 -->
<h3 id="determine-the-absorption-spectra">Determine the absorption spectra</h3>

<p>In order to obtain \(\lambda_{max}\) measure the absorbance of the diluted sample at 50 nm intervals between 350-700 nm. This will give an estimate of where the sample absorbs most (peaks) and least (valleys). I will generate them using python. Procedure requires that all measurements to be within 0-0.7 absorbance range. If maximal values are higher, sample should be diluted:</p>

<p>Data can be generated:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># absorbance of the sample at 10 nm intervals between 350-700 nm.</span>
<span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">350</span><span class="p">,</span> <span class="mi">750</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c">#random values in range 0 - 0.7</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Absorbance'</span><span class="p">])</span></code></pre></figure>

<p>Or read from file:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data/lambda_max.csv"</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s">"Absorbance"</span><span class="p">])</span></code></pre></figure>

<p>Pandas can ingest every text and binary data format, which fits RAM memory. This way I received table called DataFrame. To find basic statistics, lets call <code class="highlighter-rouge">describe()</code> method on data Frame.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
       <span class="n">Absorbance</span>
<span class="n">count</span>   <span class="mf">36.000000</span>
<span class="n">mean</span>     <span class="mf">0.355109</span>
<span class="n">std</span>      <span class="mf">0.176637</span>
<span class="nb">min</span>      <span class="mf">0.018094</span>
<span class="mi">25</span><span class="o">%</span>      <span class="mf">0.265485</span>
<span class="mi">50</span><span class="o">%</span>      <span class="mf">0.371752</span>
<span class="mi">75</span><span class="o">%</span>      <span class="mf">0.470539</span>
<span class="nb">max</span>      <span class="mf">0.683876</span></code></pre></figure>

<p>Find wavelength for which absorbance is highest (it is trivial for few arguments, but becomes more complex when amount of data grows):</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s">'Absorbance'</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
<span class="mi">410</span></code></pre></figure>

<p>And plot it to get more direct data feel:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">ax</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">Absorbance</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s">"$</span><span class="err">\</span><span class="s">lambda_{max}$ of the protein"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Absorbance"</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/2017-03-03/lambda_max.png" alt="lambda" /></p>

<h3 id="calculate-the-extinction-coefficient-epsilon-of-the-standards">Calculate the extinction coefficient (\(\epsilon\)) of the standards.</h3>

<p>The Beer-Lambert Law states that Absorbance is proportional to the concentration of the absorbing molecules, the length of light-path through the medium and the molar extinction coefficient:</p>

<script type="math/tex; mode=display">Abs = \epsilon \cdot c \cdot l</script>

<p>where:</p>

<ul>
  <li>\(Abs\) – absorbance</li>
  <li>\(\epsilon\) – light extinction coefficient at max absorption wavelength \(\lambda_{max}\)</li>
  <li>\(c\) – substance concentration</li>
  <li>\(l\) – length of light-path</li>
</ul>

<p>therefore \(\epsilon\) is equal to:</p>

<script type="math/tex; mode=display">\epsilon =  \frac{Abs_{410}}{c \cdot l}</script>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># Abs_410 = 0.683876</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.683876</span><span class="o">/</span><span class="p">(</span><span class="n">c</span><span class="o">*</span><span class="mi">1</span><span class="p">)</span></code></pre></figure>

<p>where c is concentration of the standard.</p>

<h3 id="determine-the-concentration-of-proteins-in-solution">Determine the concentration of proteins in solution</h3>

<p>Knowing epsilon just simply solve standard Beer-Lamber equation for \(c\). Another approach is to construct calibration curve from known samples, determine function, which fits data best and use it to calculate x (concentration) with known y (absorbance).</p>

<h4 id="calibration-curve">Calibration curve</h4>

<p>Consider the following example involving a set of six standard points (5, 10, 25, 30, 40, 50, 60, and 70 µg/mL). Absorbance: (0.106, 0.236, 0.544, 0.690, 0.791, 0.861, 0.882, 0.911). I have two columns of x and y values of the calibration curve points.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Conc.</th>
      <th> </th>
      <th style="text-align: right">Abs.</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">5</td>
      <td> </td>
      <td style="text-align: right">0.106</td>
    </tr>
    <tr>
      <td style="text-align: left">10</td>
      <td> </td>
      <td style="text-align: right">0.236</td>
    </tr>
    <tr>
      <td style="text-align: left">25</td>
      <td> </td>
      <td style="text-align: right">0.544</td>
    </tr>
    <tr>
      <td style="text-align: left">30</td>
      <td> </td>
      <td style="text-align: right">0.690</td>
    </tr>
    <tr>
      <td style="text-align: left">40</td>
      <td> </td>
      <td style="text-align: right">0.791</td>
    </tr>
    <tr>
      <td style="text-align: left">50</td>
      <td> </td>
      <td style="text-align: right">0.861</td>
    </tr>
    <tr>
      <td style="text-align: left">60</td>
      <td> </td>
      <td style="text-align: right">0.882</td>
    </tr>
    <tr>
      <td style="text-align: left">70</td>
      <td> </td>
      <td style="text-align: right">0.911</td>
    </tr>
  </tbody>
</table>

<p><br />
It is quite easy to plot this points to visualize data and get some general overview of their shape, like that:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c"># Calibration curve data</span>
<span class="n">concentration</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">70</span><span class="p">])</span>
<span class="n">absorbance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.106</span><span class="p">,</span> <span class="mf">0.236</span><span class="p">,</span> <span class="mf">0.544</span><span class="p">,</span> <span class="mf">0.690</span><span class="p">,</span> <span class="mf">0.791</span><span class="p">,</span> <span class="mf">0.861</span><span class="p">,</span> <span class="mf">0.882</span><span class="p">,</span> <span class="mf">0.911</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">concentration</span><span class="p">,</span> <span class="n">absorbance</span><span class="p">,</span> <span class="s">'o'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span></code></pre></figure>

<p>Not bad, six lines of code and plot is ready.</p>

<p><img src="/assets/2017-03-03/calibration-points.png" alt="calibration-points" /></p>

<h4 id="linear-fit">Linear fit</h4>

<p>To fit the data to the line I will use <code class="highlighter-rouge">scipy</code> package. Linear fit means I will try to find function with general definition:</p>

<script type="math/tex; mode=display">y = Ax + b</script>

<p>where:</p>

<ul>
  <li>\(A\) - is slope</li>
  <li>\(b\) - is intercept</li>
</ul>

<p>and specific function will have minimal error value fitted for all points with least square regression.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">concentration</span><span class="p">,</span> <span class="n">absorbance</span><span class="p">)</span></code></pre></figure>

<p>Now I will visualize standard curve points and line fitted to them:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># plot of fitted line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">concentration</span><span class="p">,</span> <span class="n">absorbance</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'data points'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">concentration</span><span class="p">,</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">slope</span><span class="o">*</span><span class="n">concentration</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'fitted line'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/2017-03-03/calibration-linear-fit.png" alt="calibration-points" /></p>

<p>For this set of points linear fitting seems to be suboptimal choice. \(R^2 = 0.8754454029810919\). Lets try other type of function - polynomial.</p>

<h4 id="polynomial-fit">Polynomial fit</h4>

<p>Polynomial fitting may better reflect character of the points. In above data set there is step increase region with more flat part at the top. It would be much better to fit other type of function, which will be able to reflect plateau at the end. Such properties have polynomials or logarithmic functions. Lets try with second degree polynomial known as quadratic function. In this case second degree polynomial is sufficient. Fitting function creates list of coefficients for least-squares fit of the data points to the polynomial function described in general as: \(p(x) = c_0 + c_1 x + … + c_n x_n\):</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c">#polynomial fit</span>
<span class="kn">from</span> <span class="nn">numpy.polynomial</span> <span class="kn">import</span> <span class="n">Polynomial</span> <span class="k">as</span> <span class="n">P</span>

<span class="n">coefs</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">concentration</span><span class="p">,</span> <span class="n">absorbance</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ffit</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">polyval</span><span class="p">(</span><span class="n">concentration</span><span class="p">,</span> <span class="n">coefs</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">concentration</span><span class="p">,</span> <span class="n">absorbance</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'data points'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">concentration</span><span class="p">,</span> <span class="n">ffit</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'fitted line'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/2017-03-03/calibration-polynomial-fit.png" alt="calibration-linear-fit" /></p>

<p>Coefficients are: -0.03969222, 0.03034985, -0.00024301. Therefore polynomial has form:</p>

<script type="math/tex; mode=display">y = -0.0396x^2 + 0.0303x - 0.00024</script>

<p>You can go ahead and write script taking third degree polynomial to fit the data, or run snippet prepared in Jupyter Notebook. As I mentioned before, there is minimal difference between quadratic and cubic fit. Both polynomials comparison should look similar to this:</p>

<p><img src="/assets/2017-03-03/polynomial-comparison.png" alt="polynomials comparison-linear-fit" /></p>

<h4 id="concnetration-interpolation">Concnetration interpolation</h4>

<p>Interpolation of the unknown sample is simple as resolving one of the functions in respect to x. In case of linear regression transformation is trivial (rounded to four decimal places):</p>

<script type="math/tex; mode=display">x = \frac{(absorbance - intercept)}{slope} = \frac{(absorbance - 0.176)}{0.0124}</script>

<p>Lets calculate concentration for 0.5 absorbance:</p>

<script type="math/tex; mode=display">x =  \frac{(0.5 - 0.176)}{0.0124} = 26.129</script>

<p>Althought this is very simple algebra, it can also be replaced by python computations. <code class="highlighter-rouge">sympy</code> module allows to perform symbolic math operations like this:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">sympy</span> <span class="kn">as</span> <span class="nn">smp</span>
<span class="n">smp</span><span class="o">.</span><span class="n">init_printing</span><span class="p">(</span><span class="n">use_unicode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">smp</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">'x y'</span><span class="p">)</span>
<span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">smp</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">'A b'</span><span class="p">,</span> <span class="nb">float</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">A</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b</span>

<span class="n">smp</span><span class="o">.</span><span class="n">solveset</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></code></pre></figure>

<script type="math/tex; mode=display">\left\{- \frac{b}{A}\right\}</script>

<p>What this lines do? First two import sympy package and set some printing options. Next identify normal python variables x, y, A, b as sympy <code class="highlighter-rouge">Symbol()</code> objects. Further expression is set and solved against x. This approach calculates exact x for y equal 0. If I substitute y with some value, I will have to change expression to:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">expr</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b</span><span class="p">)</span><span class="o">-</span><span class="n">y</span>

<span class="n">smp</span><span class="o">.</span><span class="n">solveset</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></code></pre></figure>

<script type="math/tex; mode=display">\left\{- \frac{1}{A} \left(b - y\right)\right\}</script>

<p>For second degree polynomial it is little bit more complicated. We can use well known math formula for quadratic equation roots, or ask sympy and numpy to calculate it for us.</p>

<p>To get exact symbolic solution:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">smp</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">'x y'</span><span class="p">)</span>
<span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">,</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">smp</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s">'a1 a2 a3'</span><span class="p">,</span> <span class="nb">float</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">expr</span> <span class="o">=</span> <span class="p">(</span><span class="n">a1</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">a2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">a3</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span>
<span class="n">smp</span><span class="o">.</span><span class="n">solveset</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></code></pre></figure>

<p>Which results in:</p>

<script type="math/tex; mode=display">\left\{- \frac{a_{2}}{2 a_{1}} - \frac{1}{2 a_{1}} \sqrt{- 4 a_{1} a_{3} + a_{2}^{2}}, - \frac{a_{2}}{2 a_{1}} + \frac{1}{2 a_{1}} \sqrt{- 4 a_{1} a_{3} + a_{2}^{2}}\right\}</script>

<p>For numeric solution I will solve the equation \(f(x) - y = 0\) using <code class="highlighter-rouge">np.roots</code>, where \(f(x)\) is our polynomial:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">numpy.polynomial</span> <span class="kn">import</span> <span class="n">Polynomial</span> <span class="k">as</span> <span class="n">P</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">concentration</span><span class="p">,</span> <span class="n">absorbance</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="p">(</span><span class="n">p</span> <span class="o">-</span> <span class="o">.</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">roots</span><span class="p">()</span>


<span class="n">Out</span><span class="p">[</span><span class="mi">5</span><span class="p">]:</span> 
<span class="n">array</span><span class="p">([</span>  <span class="mf">21.47501868</span><span class="p">,</span>  <span class="mf">103.41541963</span><span class="p">])</span></code></pre></figure>

<p>For absorbance equal 0.5 program returned two values: 21.47501868 and 103.41541963. Quick look at the graph shows that value we are looking for is 21.475.</p>

<p>But why there are two values and how to identify correct one? It is easy If we go back to the fitting and check what kind of function was used to fit data. I used parabola (quadratic), ascending arm of the parabola to be exact. Therefore for each point within x range (5-70) one can expect that quadratic function will have additional solution from descending arm, outside of the x scope. In reality our fitting function looks like this:</p>

<p><img src="/assets/2017-03-03/quadratic_fit.png" alt="quadratic fit full" /></p>

<p>That is why only points fitted within x data range make sense and rest is irrelevant. There is one concern, which is related to the maximum point, which may be placed within x data range and then plateau data may suffer from that, giving wrong results. Possibly for this data set. logarithmic function would be perfect. However from Beer-Lambert law we know, that only linear growth phase from 0.05 to 0.7 absorbance is relevant, thus accuracy of the asymptotic region can be neglected.</p>

<p><br /></p>

<hr />

<p>Example Jupyter notebook can be downloaded from <a href="https://github.com/mdyzma/blog-src-files/tree/master/2017-03-03-jupyter-notebook-lab-book">GitHub</a>.</p>

<hr />

<p><br />
<!-- Links --></p>

<!-- Images -->


  </div>
<div class="container">
    <div class="row ">
        <div class="col-xs-2"></div>
        <div class="col-xs-8">

        <!-- Twitter -->
        <a href="https://twitter.com/share" class="twitter-share-button" data-via="MichalDyzma">Tweet</a>
        <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

        <!-- Google + -->
        <div class="g-plus" data-action="share" data-annotation="bubble"></div>
        <script src="https://apis.google.com/js/platform.js" async defer></script>

        <!-- Facebook -->
        <div class="fb-share-button" data-href="http://localhost:4000/2017/03/03/jupyter-notebook-lab-book/" data-layout="button_count" data-size="small" data-mobile-iframe="true" style="position: relative; top: -8px;"></div>


        <div id="fb-root"></div>
        <script>(function(d, s, id) {
          var js, fjs = d.getElementsByTagName(s)[0];
          if (d.getElementById(id)) return;
            js = d.createElement(s); js.id = id;
            js.src = "//connect.facebook.net/pl_PL/sdk.js#xfbml=1&version=v2.9&appId=422251294815916";
            fjs.parentNode.insertBefore(js, fjs);
        }(document, 'script', 'facebook-jssdk'));</script>

    </div>
    </div>
    <div class="col-xs-2"></div>
</div>


<div id="disqus_thread"></div>
    <script type="text/javascript">

        var disqus_config = function () {
            this.page.url = "http://localhost:4000/2017/03/03/jupyter-notebook-lab-book/";
            this.page.identifier = "/2017/03/03/jupyter-notebook-lab-book";
        };
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'md-blog';
        var disqus_developer = 1; // Comment out when the site is live

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var d = document, s = d.createElement('script');
            s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript"></noscript>


</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <p>
      

&copy; Michal Dyzma - Powered by <a href="https://jekyllrb.com">Jekyll</a> &amp; <a href="https://github.com/yous/whiteglass">whiteglass</a> - Subscribe via <a href="http://localhost:4000/feed.xml">RSS</a>


<!-- mathjax -->

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



<!-- Bootstrap core JavaScript
================================================== -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


    </p>

  </div>

</footer>


  </body>

</html>
